17-07-2025 00:56:34:
    1) Begins the project. Current plan
        1.1) Phase 1 : Create the main brain, the main lifeline of the model, the recommendation model to find career choice. 
        1.2) Phase 2 : Creating a SHAP explanation and linking it to a generative AI model that can create explanations and give it in the form of human readable text to make it understandable. 
        1.3) Phase 3 : Creating a backend that is capable of accepting the user input and running the model to generate and send the results. 
        1.4) Phase 4 : Create a smooth frontend that can access this backend to take the input and show the results. 

17-07-2025 01:39:22:

    2) Phase 1 initialised :
        2.1) First step : Data acquisition. Source : O-NET resources for occupation data and skills. 
        2.2) Second step : Filtering the dataset to find relevant skills and job descriptions to find good jobs. 
        2.3) Third step : Creating randomised data. Number of roles as many as possible - 150 user profiles per job. 845 total jobs and 126750 user profiles made
        2.4) Training a XGBoost model to classify and predict top 3 career choices. 
    
        2.5) First attempt : 
            2.5.1) Have 845 jobs and 126750 profiles. Drastic failure with just a 10.67% accuracy. Harsh rejection.
            2.5.2) Reason : 845 classifications is a very big multi class challenge for XGBoost. 
            2.5.3) Update for next step : First, cluster similar jobs into bigger classifications and try to find the most suitable matching cluster. If the cluster is found, search for a job title within that cluster. Thus, we create a 2 stage classifier. 
        
17-07-2025 04:19:53:
        2.6) Second attempt :
            2.6.1) First painful step was to make cluster of all the jobs. Took almost 3 hours but it is done now. Was idiotically doing it manually but then, I realised a semantic analysis can be done for all the jobs. 
            
            

All files : 
    1) Dataset/Occupation_Data.txt and Skills.txt : Raw data from ONet : https://www.onetcenter.org/database.html
    2) Dataset/unique_job_list.csv : List of all unique 845 jobs in our database 
    3) Phase1_Model_Creation/career_profiles.csv : Randomly created job profiles with interests, skills and job labels
    4) Phase1_Model_Creation/clustered_job_titles.csv : Classifying the jobs into suitable clusters
    5) Phase1_Model_Creation/final_dataset.csv : Merging 3 and 4
    6) Phase1_Model_Creation/P1_brainA1.py : First attempt in making the model. Reference 2.5
    7) Phase1_Model_Creation/P1_brainA2.py : Second attempt in making the model. Reference 2.6
    8) Phase1_Model_Creation/P1_merger.py : Merging 3 and 4
    9) Phase1_Model_Creation/P1_Job_Title_Clustering.py : Semantic analysis to classify the jobs into clusters 
    10) Preprocess/Get_Unique.py : Get list of all unique jobs
    11) Preprocess/Profile_Generator.py : Generate random profiles (150 per job title)